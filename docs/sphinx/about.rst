About
=====

**anira** is a C++ library engineered to facilitate the development of real-time audio applications that seamlessly integrate neural network inference. It delivers a high-performance, real-time safe execution environment for neural networks, ensuring deterministic runtimes that meet the stringent demands of professional audio processing.

The neural network inference is powered by industry-standard inference engines, including LibTorch, ONNXRuntime, and TensorFlow Lite. anira provides a unified interface to these engines through the :cpp:class:`anira::InferenceHandler` class, while delegating inference execution to a static thread pool. This architecture maintains real-time safety in audio processing callbacks by executing inference without blocking the audio thread, ensuring applications remain consistently responsive and deterministic. Furthermore, this design enables anira to harness multiple CPU cores for efficient parallel inference execution.

anira is meticulously designed to minimize latency while supporting predefined tensor shapes for neural networks. A cornerstone feature is the intelligent adaptation of host audio buffers to neural network input and output tensors, with automatic calculation of the minimum required latency based on the :cpp:struct:`anira::InferenceConfig` struct. When neural network processing exceeds the predefined latency threshold, anira catches up missing frames, maintaining smooth and synchronized audio processing.

Neural network model inputs and outputs can be preprocessed and postprocessed with built-in functionality. When custom data handling is required, developers can implement specialized preprocessing and postprocessing logic by extending the :cpp:class:`anira::PrePostProcessor` class. This flexibility empowers developers to tailor data handling to their specific application requirements, ensuring neural network models receive appropriately formatted data and that results are correctly interpreted within the audio processing pipeline.

The library accommodates diverse neural network architectures, supporting both stateful and stateless models. Models can employ single or multiple input and output tensors, enabling flexible integration of sophisticated neural network architectures. These tensors are categorized as either streamable or non-streamable, based on their data characteristics. Streamable tensors process time-varying data such as audio signals, while non-streamable tensors handle static parameters requiring asynchronous updates. Since anira version 2.0, the library supports input and output tensors with varying sizes and sampling rates, unlocking more complex processing scenarios and enhanced architectural flexibility.

anira also includes built-in benchmarking capabilities, allowing developers to evaluate the performance of their neural networks in the same environment as their audio applications. This feature is essential for optimizing applications and ensuring they meet the stringent requirements of real-time audio processing.

But anira is not necessary just about audio processing; it can also be used in other real-time applications, such as robotics and computer vision, where streamable and non-streamable data processing is required. Its design principles and real-time safety features make it a versatile tool for developers across various domains.